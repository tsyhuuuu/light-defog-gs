{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a44064",
   "metadata": {},
   "source": [
    "# 霧ガウシアンデータの最適輸送解析チュートリアル\n",
    "\n",
    "このチュートリアルでは、霧のガウシアンデータに対して最適輸送（Optimal Transport）理論を用いた解析を行う方法を学びます。\n",
    "\n",
    "## 目次\n",
    "1. [準備と環境設定](#準備と環境設定)\n",
    "2. [データの理解](#データの理解)\n",
    "3. [基本的な解析](#基本的な解析)\n",
    "4. [可視化](#可視化)\n",
    "5. [応用例](#応用例)\n",
    "6. [実践的な使用例](#実践的な使用例)\n",
    "\n",
    "---\n",
    "\n",
    "## 準備と環境設定\n",
    "\n",
    "### 必要なライブラリのインストール\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### インポートとデータの準備\n",
    "\n",
    "```python\n",
    "from gaussian_ot_analysis import GaussianFogOTAnalysis\n",
    "from visualization import FogOTVisualization\n",
    "from applications import FogOTApplications\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "csv_path = \"../../data/train_fog_all.csv\"\n",
    "analyzer = GaussianFogOTAnalysis(csv_path)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## データの理解\n",
    "\n",
    "### 使用する特徴量\n",
    "\n",
    "本チュートリアルでは、以下の特徴量のみを使用します：\n",
    "\n",
    "- **opacity**: 不透明度（霧の濃度）\n",
    "- **scale_x, scale_y, scale_z**: スケールパラメータ（霧の広がり）\n",
    "- **f_dc_0, f_dc_1, f_dc_2**: 色係数（霧の色）\n",
    "\n",
    "位置（position）と回転（rotation）は使用しません。\n",
    "\n",
    "### データの確認\n",
    "\n",
    "```python\n",
    "# 霧データの基本情報を確認\n",
    "print(f\"霧ガウシアンの総数: {len(analyzer.fog_gaussians['opacity'])}\")\n",
    "print(f\"不透明度の範囲: {analyzer.fog_gaussians['opacity'].min():.3f} - {analyzer.fog_gaussians['opacity'].max():.3f}\")\n",
    "\n",
    "# スケールの確認\n",
    "scales = analyzer.fog_gaussians['scale']\n",
    "print(f\"スケールの平均: {np.mean(scales, axis=0)}\")\n",
    "\n",
    "# 色の確認\n",
    "colors = analyzer.fog_gaussians['color']\n",
    "print(f\"色の範囲: RGB({colors.min(axis=0)}, {colors.max(axis=0)})\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 基本的な解析\n",
    "\n",
    "### 1. 不透明度ベースの解析\n",
    "\n",
    "高密度霧と低密度霧の分布を最適輸送で比較します：\n",
    "\n",
    "```python\n",
    "# 不透明度による解析\n",
    "opacity_result = analyzer.opacity_based_ot_analysis()\n",
    "\n",
    "print(f\"高密度霧と低密度霧間のワッサーシュタイン距離: {opacity_result['wasserstein_distance']:.4f}\")\n",
    "print(f\"高密度霧の数: {len(opacity_result['high_opacity_values'])}\")\n",
    "print(f\"低密度霧の数: {len(opacity_result['low_opacity_values'])}\")\n",
    "```\n",
    "\n",
    "### 2. 多次元特徴解析\n",
    "\n",
    "不透明度、スケール、色を組み合わせた解析：\n",
    "\n",
    "```python\n",
    "# 多次元特徴解析を実行\n",
    "multi_result = analyzer.multi_feature_ot_analysis()\n",
    "print(f\"多次元ワッサーシュタイン距離: {multi_result['wasserstein_distance']:.6f}\")\n",
    "```\n",
    "\n",
    "### 3. カスタム特徴解析関数\n",
    "\n",
    "位置と回転を除外した新しい解析関数を定義：\n",
    "\n",
    "```python\n",
    "def analyze_fog_features_only(analyzer):\n",
    "    \"\"\"\n",
    "    不透明度、スケール、色のみを使用した解析\n",
    "    \"\"\"\n",
    "    # 特徴量の抽出\n",
    "    opacities = analyzer.fog_gaussians['opacity'].reshape(-1, 1)\n",
    "    scales = analyzer.fog_gaussians['scale']  # 3次元\n",
    "    colors = analyzer.fog_gaussians['color']  # 3次元\n",
    "    \n",
    "    # スケールの大きさを計算\n",
    "    scale_magnitudes = np.linalg.norm(scales, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # 特徴量を結合（不透明度 + スケール大きさ + 色）\n",
    "    features = np.hstack([\n",
    "        opacities / np.std(opacities),  # 正規化\n",
    "        scale_magnitudes / np.std(scale_magnitudes),\n",
    "        colors / np.std(colors, axis=0)\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# カスタム解析の実行\n",
    "features = analyze_fog_features_only(analyzer)\n",
    "print(f\"使用した特徴量の次元: {features.shape[1]}\")\n",
    "print(f\"特徴量: [不透明度, スケール大きさ, R, G, B]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 可視化\n",
    "\n",
    "### 1. 基本的な可視化\n",
    "\n",
    "```python\n",
    "# 可視化オブジェクトの作成\n",
    "visualizer = FogOTVisualization(analyzer)\n",
    "\n",
    "# 不透明度解析の可視化\n",
    "opacity_result = analyzer.opacity_based_ot_analysis()\n",
    "fig_opacity = visualizer.plot_opacity_analysis(opacity_result)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. カスタム可視化関数\n",
    "\n",
    "```python\n",
    "def plot_fog_features_analysis(analyzer):\n",
    "    \"\"\"\n",
    "    不透明度、スケール、色の分布を可視化\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 不透明度分布\n",
    "    axes[0, 0].hist(analyzer.fog_gaussians['opacity'], bins=50, alpha=0.7, color='blue')\n",
    "    axes[0, 0].set_xlabel('不透明度')\n",
    "    axes[0, 0].set_ylabel('頻度')\n",
    "    axes[0, 0].set_title('不透明度の分布')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # スケール分布\n",
    "    scales = analyzer.fog_gaussians['scale']\n",
    "    scale_magnitudes = np.linalg.norm(scales, axis=1)\n",
    "    axes[0, 1].hist(scale_magnitudes, bins=50, alpha=0.7, color='green')\n",
    "    axes[0, 1].set_xlabel('スケール大きさ')\n",
    "    axes[0, 1].set_ylabel('頻度')\n",
    "    axes[0, 1].set_title('スケールの分布')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 色分布（RGB）\n",
    "    colors = analyzer.fog_gaussians['color']\n",
    "    axes[1, 0].hist(colors[:, 0], bins=50, alpha=0.7, color='red', label='R')\n",
    "    axes[1, 0].hist(colors[:, 1], bins=50, alpha=0.7, color='green', label='G')\n",
    "    axes[1, 0].hist(colors[:, 2], bins=50, alpha=0.7, color='blue', label='B')\n",
    "    axes[1, 0].set_xlabel('色値')\n",
    "    axes[1, 0].set_ylabel('頻度')\n",
    "    axes[1, 0].set_title('色の分布')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 不透明度とスケールの関係\n",
    "    axes[1, 1].scatter(analyzer.fog_gaussians['opacity'], scale_magnitudes, \n",
    "                       alpha=0.6, s=10)\n",
    "    axes[1, 1].set_xlabel('不透明度')\n",
    "    axes[1, 1].set_ylabel('スケール大きさ')\n",
    "    axes[1, 1].set_title('不透明度とスケールの関係')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# カスタム可視化の実行\n",
    "fig_custom = plot_fog_features_analysis(analyzer)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 応用例\n",
    "\n",
    "### 1. 霧の品質評価（特徴量限定版）\n",
    "\n",
    "```python\n",
    "class FogQualityAssessmentLimited:\n",
    "    \"\"\"\n",
    "    不透明度、スケール、色のみを使用した霧品質評価\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer):\n",
    "        self.analyzer = analyzer\n",
    "    \n",
    "    def assess_fog_consistency(self):\n",
    "        \"\"\"霧の一貫性評価\"\"\"\n",
    "        # 不透明度の一貫性\n",
    "        opacities = self.analyzer.fog_gaussians['opacity']\n",
    "        opacity_consistency = 1.0 / (1.0 + np.std(opacities) / np.mean(opacities))\n",
    "        \n",
    "        # スケールの一貫性\n",
    "        scales = self.analyzer.fog_gaussians['scale']\n",
    "        scale_magnitudes = np.linalg.norm(scales, axis=1)\n",
    "        scale_consistency = 1.0 / (1.0 + np.std(scale_magnitudes) / np.mean(scale_magnitudes))\n",
    "        \n",
    "        # 色の一貫性\n",
    "        colors = self.analyzer.fog_gaussians['color']\n",
    "        color_std = np.mean(np.std(colors, axis=0))\n",
    "        color_consistency = 1.0 / (1.0 + color_std)\n",
    "        \n",
    "        # 総合スコア\n",
    "        overall_score = (opacity_consistency + scale_consistency + color_consistency) / 3\n",
    "        \n",
    "        return {\n",
    "            'opacity_consistency': opacity_consistency,\n",
    "            'scale_consistency': scale_consistency,\n",
    "            'color_consistency': color_consistency,\n",
    "            'overall_score': overall_score\n",
    "        }\n",
    "\n",
    "# 品質評価の実行\n",
    "quality_assessor = FogQualityAssessmentLimited(analyzer)\n",
    "quality_result = quality_assessor.assess_fog_consistency()\n",
    "\n",
    "print(\"=== 霧品質評価結果 ===\")\n",
    "print(f\"不透明度の一貫性: {quality_result['opacity_consistency']:.4f}\")\n",
    "print(f\"スケールの一貫性: {quality_result['scale_consistency']:.4f}\")\n",
    "print(f\"色の一貫性: {quality_result['color_consistency']:.4f}\")\n",
    "print(f\"総合スコア: {quality_result['overall_score']:.4f}\")\n",
    "```\n",
    "\n",
    "### 2. 特徴量ベースの異常検出\n",
    "\n",
    "```python\n",
    "def detect_fog_anomalies_by_features(analyzer, contamination=0.05):\n",
    "    \"\"\"\n",
    "    不透明度、スケール、色を使用した異常検出\n",
    "    \"\"\"\n",
    "    # 特徴量の準備\n",
    "    opacities = analyzer.fog_gaussians['opacity'].reshape(-1, 1)\n",
    "    scales = analyzer.fog_gaussians['scale']\n",
    "    colors = analyzer.fog_gaussians['color']\n",
    "    \n",
    "    # 特徴量を結合\n",
    "    features = np.hstack([\n",
    "        opacities / np.std(opacities),\n",
    "        scales / np.std(scales, axis=0),\n",
    "        colors / np.std(colors, axis=0)\n",
    "    ])\n",
    "    \n",
    "    # 各サンプルの異常度を計算（他のサンプルとの平均距離）\n",
    "    n_samples = len(features)\n",
    "    anomaly_scores = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        distances = np.linalg.norm(features - features[i], axis=1)\n",
    "        anomaly_scores[i] = np.mean(distances)\n",
    "    \n",
    "    # 閾値の設定\n",
    "    threshold = np.percentile(anomaly_scores, (1 - contamination) * 100)\n",
    "    anomalies = anomaly_scores > threshold\n",
    "    \n",
    "    return {\n",
    "        'anomaly_scores': anomaly_scores,\n",
    "        'anomalies': anomalies,\n",
    "        'threshold': threshold,\n",
    "        'anomaly_indices': np.where(anomalies)[0]\n",
    "    }\n",
    "\n",
    "# 異常検出の実行\n",
    "anomaly_result = detect_fog_anomalies_by_features(analyzer)\n",
    "n_anomalies = len(anomaly_result['anomaly_indices'])\n",
    "\n",
    "print(f\"検出された異常な霧パターン: {n_anomalies}個\")\n",
    "print(f\"異常率: {n_anomalies/len(analyzer.fog_gaussians['opacity'])*100:.2f}%\")\n",
    "print(f\"異常度閾値: {anomaly_result['threshold']:.4f}\")\n",
    "```\n",
    "\n",
    "### 3. 霧の分類\n",
    "\n",
    "```python\n",
    "def classify_fog_by_characteristics(analyzer, n_classes=4):\n",
    "    \"\"\"\n",
    "    特徴量による霧の分類\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # 特徴量の準備\n",
    "    opacities = analyzer.fog_gaussians['opacity'].reshape(-1, 1)\n",
    "    scales = analyzer.fog_gaussians['scale']\n",
    "    colors = analyzer.fog_gaussians['color']\n",
    "    \n",
    "    # 特徴量を結合\n",
    "    features = np.hstack([opacities, scales, colors])\n",
    "    \n",
    "    # 標準化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # クラスタリング\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=42)\n",
    "    labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    # 各クラスタの特徴を分析\n",
    "    cluster_stats = {}\n",
    "    for i in range(n_classes):\n",
    "        mask = labels == i\n",
    "        if np.any(mask):\n",
    "            cluster_stats[f'クラスタ{i+1}'] = {\n",
    "                '数': np.sum(mask),\n",
    "                '平均不透明度': np.mean(analyzer.fog_gaussians['opacity'][mask]),\n",
    "                '平均スケール': np.mean(np.linalg.norm(scales[mask], axis=1)),\n",
    "                '平均色': np.mean(colors[mask], axis=0)\n",
    "            }\n",
    "    \n",
    "    return labels, cluster_stats\n",
    "\n",
    "# 分類の実行\n",
    "labels, cluster_stats = classify_fog_by_characteristics(analyzer)\n",
    "\n",
    "print(\"=== 霧の分類結果 ===\")\n",
    "for cluster_name, stats in cluster_stats.items():\n",
    "    print(f\"\\n{cluster_name}:\")\n",
    "    print(f\"  数: {stats['数']}\")\n",
    "    print(f\"  平均不透明度: {stats['平均不透明度']:.4f}\")\n",
    "    print(f\"  平均スケール: {stats['平均スケール']:.4f}\")\n",
    "    print(f\"  平均色 (RGB): [{stats['平均色'][0]:.3f}, {stats['平均色'][1]:.3f}, {stats['平均色'][2]:.3f}]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 実践的な使用例\n",
    "\n",
    "### 完全な解析パイプライン\n",
    "\n",
    "```python\n",
    "def complete_fog_analysis_pipeline(csv_path):\n",
    "    \"\"\"\n",
    "    霧データの完全な解析パイプライン\n",
    "    \"\"\"\n",
    "    print(\"=== 霧ガウシアンデータ解析 ===\\n\")\n",
    "    \n",
    "    # 1. データの読み込み\n",
    "    print(\"1. データを読み込み中...\")\n",
    "    analyzer = GaussianFogOTAnalysis(csv_path)\n",
    "    \n",
    "    # 2. 基本統計\n",
    "    print(\"2. 基本統計情報:\")\n",
    "    opacities = analyzer.fog_gaussians['opacity']\n",
    "    scales = analyzer.fog_gaussians['scale']\n",
    "    colors = analyzer.fog_gaussians['color']\n",
    "    \n",
    "    print(f\"   霧ガウシアン数: {len(opacities)}\")\n",
    "    print(f\"   不透明度: 平均={np.mean(opacities):.4f}, 標準偏差={np.std(opacities):.4f}\")\n",
    "    print(f\"   スケール: 平均={np.mean(np.linalg.norm(scales, axis=1)):.4f}\")\n",
    "    print(f\"   色: R={np.mean(colors[:, 0]):.3f}, G={np.mean(colors[:, 1]):.3f}, B={np.mean(colors[:, 2]):.3f}\")\n",
    "    \n",
    "    # 3. 品質評価\n",
    "    print(\"\\n3. 品質評価:\")\n",
    "    quality_assessor = FogQualityAssessmentLimited(analyzer)\n",
    "    quality_result = quality_assessor.assess_fog_consistency()\n",
    "    print(f\"   総合品質スコア: {quality_result['overall_score']:.4f}\")\n",
    "    \n",
    "    # 4. 異常検出\n",
    "    print(\"\\n4. 異常検出:\")\n",
    "    anomaly_result = detect_fog_anomalies_by_features(analyzer)\n",
    "    n_anomalies = len(anomaly_result['anomaly_indices'])\n",
    "    print(f\"   異常パターン: {n_anomalies}個 ({n_anomalies/len(opacities)*100:.2f}%)\")\n",
    "    \n",
    "    # 5. 分類\n",
    "    print(\"\\n5. 霧の分類:\")\n",
    "    labels, cluster_stats = classify_fog_by_characteristics(analyzer)\n",
    "    for cluster_name, stats in cluster_stats.items():\n",
    "        print(f\"   {cluster_name}: {stats['数']}個\")\n",
    "    \n",
    "    # 6. 可視化\n",
    "    print(\"\\n6. 可視化を生成中...\")\n",
    "    fig = plot_fog_features_analysis(analyzer)\n",
    "    fig.savefig('fog_analysis/ot/fog_features_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\n解析完了！結果は fog_analysis/ot/ に保存されました。\")\n",
    "    \n",
    "    return {\n",
    "        'analyzer': analyzer,\n",
    "        'quality': quality_result,\n",
    "        'anomalies': anomaly_result,\n",
    "        'classification': (labels, cluster_stats)\n",
    "    }\n",
    "\n",
    "# パイプラインの実行\n",
    "if __name__ == \"__main__\":\n",
    "    results = complete_fog_analysis_pipeline(\"../../data/train_fog_all.csv\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 注意事項とヒント\n",
    "\n",
    "### 1. パフォーマンスの最適化\n",
    "\n",
    "```python\n",
    "# 大きなデータセットの場合はサブサンプリングを使用\n",
    "def subsample_fog_data(analyzer, sample_size=10000):\n",
    "    \"\"\"霧データのサブサンプリング\"\"\"\n",
    "    n_total = len(analyzer.fog_gaussians['opacity'])\n",
    "    if n_total > sample_size:\n",
    "        indices = np.random.choice(n_total, sample_size, replace=False)\n",
    "        for key in analyzer.fog_gaussians:\n",
    "            if len(analyzer.fog_gaussians[key].shape) == 1:\n",
    "                analyzer.fog_gaussians[key] = analyzer.fog_gaussians[key][indices]\n",
    "            else:\n",
    "                analyzer.fog_gaussians[key] = analyzer.fog_gaussians[key][indices]\n",
    "    return analyzer\n",
    "```\n",
    "\n",
    "### 2. 結果の保存\n",
    "\n",
    "```python\n",
    "def save_analysis_results(results, output_dir=\"fog_analysis/ot/results\"):\n",
    "    \"\"\"解析結果をCSVファイルに保存\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 品質評価結果\n",
    "    quality_df = pd.DataFrame([results['quality']])\n",
    "    quality_df.to_csv(f\"{output_dir}/quality_assessment.csv\", index=False)\n",
    "    \n",
    "    # 異常検出結果\n",
    "    anomaly_df = pd.DataFrame({\n",
    "        'anomaly_score': results['anomalies']['anomaly_scores'],\n",
    "        'is_anomaly': results['anomalies']['anomalies']\n",
    "    })\n",
    "    anomaly_df.to_csv(f\"{output_dir}/anomaly_detection.csv\", index=False)\n",
    "    \n",
    "    print(f\"結果を {output_dir} に保存しました。\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## まとめ\n",
    "\n",
    "このチュートリアルでは、霧のガウシアンデータの不透明度、スケール、色特徴量を使用した最適輸送解析の方法を学びました。主な学習内容：\n",
    "\n",
    "1. **基本解析**: 不透明度ベースの比較と多次元特徴解析\n",
    "2. **可視化**: 特徴量分布の可視化と関係性の分析\n",
    "3. **応用**: 品質評価、異常検出、分類\n",
    "4. **実践**: 完全な解析パイプラインの構築\n",
    "\n",
    "これらの手法を使用することで、霧データの特性を深く理解し、品質改善や異常パターンの検出に活用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd868b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
