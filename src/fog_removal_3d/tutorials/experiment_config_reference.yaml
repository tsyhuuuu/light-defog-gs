# Enhanced Experiment Configuration for Multi-Dataset Fog Gaussian Classification

# Dataset Configuration
dataset:
  data_directory: "data"  # Directory containing multiple CSV files
  cache_directory: "cache"
  file_pattern: "*.csv"  # Pattern to match CSV files
  recursive_search: true
  
  # Data splitting strategies
  splitting:
    strategy: "combined"  # Options: "combined", "cross_dataset", "parameter_based"
    test_size: 0.2
    validation_size: 0.1
    random_state: 42
    
    # Cross-validation settings
    cv_folds: 5
    cv_strategy: "stratified"  # Options: "stratified", "kfold", "group"
    
  # Feature Selection Configuration
  features:
    # Feature selection mode
    selection_mode: "auto"  # Options: "auto", "manual", "exclude", "statistical"
    
    # Manual feature selection (when selection_mode: "manual")
    manual_features: [
      # Basic Gaussian properties
      "f_dc_0", "f_dc_1", "f_dc_2",      # Spherical harmonics (color)
      "scale_x", "scale_y", "scale_z",    # Scale parameters
      "opacity",                          # Opacity
      
      # Spatial neighborhood features (k-nearest neighbors)
      "knn_6_mean_distance", "knn_6_std_distance", "knn_6_density",
      "knn_6_mean_opacity", "knn_6_std_opacity",
      "knn_12_mean_distance", "knn_12_std_distance", "knn_12_density",
      "knn_12_mean_opacity", "knn_12_std_opacity",
      
      # Radius-based features
      "radius_0.2_count", "radius_0.2_density", "radius_0.2_mean_opacity",
      "radius_0.6_count", "radius_0.6_density", "radius_0.6_mean_opacity",
      
      # Geometric features
      "local_linearity", "local_planarity", "local_sphericity",
      "distance_from_center", "height_percentile",
      
      # Scale context features
      "scale_x_neighborhood_ratio", "scale_y_neighborhood_ratio", "scale_z_neighborhood_ratio"
    ]
    
    # Features to exclude (when selection_mode: "exclude")
    exclude_features: [
      # Always excluded (target and metadata)
      "beta", "alpha", "is_fog", "id", "source_dataset",
      # Spatial coordinates (often excluded for generalization)
      "pos_x", "pos_y", "pos_z",
      # Rotation parameters (often noisy)
      "rot_0", "rot_1", "rot_2", "rot_3"
    ]
    
    # Statistical feature selection (when selection_mode: "statistical")
    statistical_selection:
      method: "mutual_info"  # Options: "mutual_info", "chi2", "f_classif", "variance"
      k_best: 20  # Number of best features to select
      threshold: 0.01  # Minimum score threshold
      
    # Feature categories for easy selection
    feature_categories:
      basic: ["f_dc_0", "f_dc_1", "f_dc_2", "scale_x", "scale_y", "scale_z", "opacity"]
      spatial: ["pos_x", "pos_y", "pos_z", "distance_from_center", "height_percentile"]
      rotation: ["rot_0", "rot_1", "rot_2", "rot_3"]
      neighborhood: [
        "knn_6_mean_distance", "knn_6_std_distance", "knn_6_density", "knn_6_mean_opacity",
        "knn_12_mean_distance", "knn_12_std_distance", "knn_12_density", "knn_12_mean_opacity",
        "radius_0.2_count", "radius_0.2_density", "radius_0.2_mean_opacity",
        "radius_0.6_count", "radius_0.6_density", "radius_0.6_mean_opacity"
      ]
      geometric: ["local_linearity", "local_planarity", "local_sphericity"]
      context: ["scale_x_neighborhood_ratio", "scale_y_neighborhood_ratio", "scale_z_neighborhood_ratio"]
      
    # Category-based selection (alternative to manual)
    use_categories: []  # e.g., ["basic", "neighborhood", "geometric"]
    
  # Data preprocessing
  preprocessing:
    normalize_features: true
    handle_missing: "drop"  # Options: "drop", "impute", "keep"
    outlier_detection: false
    feature_selection_validation: true  # Validate selected features exist in data
    max_samples_per_dataset: -1  # -1 for no limit

# Experiment Configuration
experiment:
  name: "fog_gaussian_classification"
  description: "Multi-dataset fog Gaussian classification experiment"
  output_directory: "experiments"
  save_intermediate_results: true
  
  # Methods to run
  methods: ["svm", "lightgbm", "deep_learning"]  # Or ["all"]
  
  # Parallel execution
  parallel:
    enable: true
    max_workers: 4
    
  # Model evaluation
  evaluation:
    metrics: ["accuracy", "precision", "recall", "f1", "auc"]
    cross_validate: true
    save_predictions: true
    save_probabilities: true
    
  # Results aggregation
  aggregation:
    create_ensemble: true
    voting_strategy: "soft"  # Options: "hard", "soft"
    ensemble_weights: "auto"  # Options: "auto", "uniform", or list of weights

# Model Configurations
models:
  svm:
    enabled: true
    hyperparameters:
      kernel: ["rbf", "linear"]
      C: [0.1, 1.0, 10.0]
      gamma: ["scale", "auto"]
    
  lightgbm:
    enabled: true
    hyperparameters:
      n_estimators: [100, 200, 300]
      learning_rate: [0.05, 0.1, 0.15]
      max_depth: [-1, 10, 20]
      num_leaves: [31, 63, 127]
      subsample: [0.8, 0.9, 1.0]
      colsample_bytree: [0.8, 0.9, 1.0]
      
  deep_learning:
    enabled: true
    
    # Training configuration
    training:
      epochs: 1000
      batch_size: 1024
      learning_rate: 0.001
      weight_decay: 1e-4
      optimizer: "adam"
      scheduler: "reduce_on_plateau"
      patience: 50
      min_delta: 1e-4
      
    # Model architectures
    architectures:
      mlp:
        enabled: true
        hidden_layers: [1024, 512, 256, 128, 32]
        dropout: 0.3
        activation: "selu"
      
      cnn1d:
        enabled: true
        channels: [64, 128, 256, 128, 64]
        kernel_sizes: [3, 3, 3, 3, 3]
        dropout: 0.2
        
      lstm:
        enabled: true
        hidden_size: 256
        num_layers: 3
        dropout: 0.3
        bidirectional: true
        
      transformer:
        enabled: true
        d_model: 256
        nhead: 8
        num_layers: 4
        dim_feedforward: 512
        dropout: 0.1
        

# Hyperparameter Tuning
hyperparameter_tuning:
  enabled: false
  method: "grid_search"  # Options: "grid_search", "random_search", "bayesian"
  cv_folds: 3
  n_trials: 50  # For bayesian optimization
  timeout: 3600  # Timeout in seconds
  
  # Search spaces (for random/bayesian search)
  search_spaces:
    svm:
      C: {"type": "loguniform", "low": 0.01, "high": 100}
      gamma: {"type": "loguniform", "low": 1e-5, "high": 1e-1}
    
    lightgbm:
      n_estimators: {"type": "int", "low": 50, "high": 500}
      learning_rate: {"type": "uniform", "low": 0.01, "high": 0.3}
      max_depth: {"type": "int", "low": 3, "high": 20}

# Hardware Configuration
hardware:
  device: "auto"  # auto, cpu, cuda, mps
  mixed_precision: false
  num_workers: 4
  pin_memory: true
  
  # Memory management
  memory:
    max_memory_gb: 16
    chunk_size: 10000  # For large datasets
    garbage_collect: true

# Logging and Monitoring
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_to_file: true
  log_to_console: true
  log_file: "experiments/experiment.log"
  
  # Progress tracking
  progress:
    show_progress_bars: true
    update_frequency: 100
    save_checkpoints: true
    checkpoint_frequency: 10  # Save every N epochs
    
  # Metrics tracking
  tracking:
    use_mlflow: false
    use_tensorboard: false
    use_wandb: false
    save_plots: true
    plot_format: "png"  # png, pdf, svg

# Results Configuration
results:
  save_models: true
  save_best_only: true
  model_format: "pkl"  # For sklearn models
  
  # Output formats
  output:
    save_csv: true
    save_json: true
    save_plots: true
    create_report: true
    report_format: "html"  # html, pdf
    
  # Visualization
  visualization:
    create_confusion_matrices: true
    create_roc_curves: true
    create_pr_curves: true
    create_feature_importance: true
    create_learning_curves: true
    create_comparison_plots: true
    
    # Plot styling
    style: "seaborn-v0_8"
    figure_size: [10, 8]
    dpi: 300
    color_palette: "Set2"

# Advanced Features
advanced:
  # Dataset balancing
  balancing:
    enabled: false
    method: "smote"  # Options: "smote", "adasyn", "random_oversample", "random_undersample"
    
  # Feature engineering
  feature_engineering:
    enabled: false
    polynomial_features: false
    interaction_features: false
    feature_selection: false
    selection_method: "mutual_info"  # Options: "mutual_info", "chi2", "f_classif"
    k_best: 50
    
  # Model interpretation
  interpretation:
    enabled: false
    methods: ["shap", "lime"]  # Explainability methods
    sample_size: 1000  # Number of samples for interpretation
    
  # Ensemble methods
  ensemble:
    enabled: false
    methods: ["voting", "stacking", "blending"]
    meta_learner: "logistic_regression"  # For stacking
    
# Reproducibility
reproducibility:
  set_seeds: true
  seed: 42
  deterministic: true  # For PyTorch
  benchmark: false  # For PyTorch CUDNN

# Error Handling
error_handling:
  continue_on_error: true
  max_retries: 3
  timeout_per_model: 7200  # 2 hours
  memory_cleanup: true