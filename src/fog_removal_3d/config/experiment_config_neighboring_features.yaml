# Example Configuration: Using Neighborhood and Spatial Features
# This config demonstrates category-based feature selection

# Dataset Configuration  
dataset:
  data_directory: "/home/tsy/Documents/TeamM_Defog/kpro-dehaze/data/csv/train/dataset_spatial"
  cache_directory: "cache"
  file_pattern: "*.csv"
  recursive_search: true
  
  splitting:
    strategy: "combined"
    test_size: 0.2
    validation_size: 0.1
    random_state: 42
    cv_folds: 5
    cv_strategy: "stratified"
    
  # Category-based Feature Selection
  features:
    selection_mode: "manual"
    manual_features: [
      # Core Gaussian properties only
      "f_dc_0", "f_dc_1", "f_dc_2", "scale_x", "scale_y", "scale_z", "opacity",     # Basic Gaussian properties
      'knn_10_mean_distance', 'knn_10_std_distance', 'knn_10_max_distance', 'knn_10_min_distance', 'knn_10_density', 'knn_10_mean_opacity', 'knn_10_std_opacity', 'knn_10_scale_x_std', 'knn_10_scale_y_std', 'knn_10_scale_z_std', # KNN-based features
      'radius_0.5_count', 'radius_0.5_density', 'radius_0.5_mean_opacity', 'radius_0.5_mean_distance', # Radius-based features
      'local_linearity', 'local_planarity', 'local_sphericity', # Geometric features
      'scale_x_neighborhood_ratio', 'scale_y_neighborhood_ratio', 'scale_z_neighborhood_ratio' # Scale ratios
    ]
      
  preprocessing:
    normalize_features: false
    handle_missing: "drop"
    feature_selection_validation: true

# Experiment Configuration
experiment:
  name: "fog_classification_neighborhood_features"
  description: "Classification using basic + neighborhood + geometric features"
  output_directory: "experiments"
  methods: ["lightgbm", "deep_learning"]
  
  evaluation:
    metrics: ["accuracy", "precision", "recall", "f1", "auc"]
    cross_validate: true

# Model Configurations
models:
  svm:
    enabled: false
    hyperparameters:
      kernel: ["rbf"]
      C: [0.1, 1.0, 10.0]
      gamma: ["scale", "auto"]
      
  lightgbm:
    enabled: true
    hyperparameters:
      n_estimators: [100, 200, 300]
      learning_rate: [0.05, 0.1, 0.15]
      max_depth: [-1, 10, 20]
      num_leaves: [31, 63, 127]
      subsample: [0.8, 0.9, 1.0]
      colsample_bytree: [0.8, 0.9, 1.0]
      
  deep_learning:
    enabled: true
    
    # Training configuration
    training:
      epochs: 500
      batch_size: 1024
      learning_rate: 0.0012
      weight_decay: 1e-4
      optimizer: "adam"
      scheduler: "reduce_on_plateau"
      patience: 75
      min_delta: 1e-4
      
    # Model architectures
    architectures:
      mlp:
        enabled: true
        hidden_layers: [784, 392, 256, 128, 32]
        dropout: 0.2
        activation: "selu"
        
      transformer:
        enabled: true
        d_model: 256
        nhead: 8
        num_layers: 4
        dim_feedforward: 512
        dropout: 0.1
        
      lstm:
        enabled: false
      cnn1d:
        enabled: false

# Hardware
hardware:
  device: "auto"
  num_workers: 4

# Logging
logging:
  level: "INFO"
  save_plots: true